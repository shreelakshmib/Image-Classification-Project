{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching : Saree\n",
      "Downloaded  306  images of  Saree \n",
      "\n",
      "Searching : Trousers for Women\n",
      "Downloaded  306  images of  Trousers for Women \n",
      "\n",
      "Searching : Jeans For Men\n",
      "Downloaded  306  images of  Jeans For Men \n",
      "\n"
     ]
    }
   ],
   "source": [
    "driver= webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "clothes = ['Saree', 'Trousers for Women', 'Jeans For Men']\n",
    "\n",
    "directory = \"C://Internship Projects/Projects/Image Scraping and Classification Project/Images/\"\n",
    "\n",
    "for c in clothes:\n",
    "    \n",
    "    img_list = []\n",
    "    product_urls = []\n",
    "    url = \"https://www.amazon.com/s?k=\"\n",
    "    \n",
    "    product = c.lower()\n",
    "    product = product.replace(\" \",\"+\")\n",
    "    print(\"Searching : \" + c )\n",
    "   \n",
    "    #create separate directories for each product\n",
    "    try:    \n",
    "        path = directory + product\n",
    "        os.makedirs(path)\n",
    "    except FileExistsError:\n",
    "        path = directory + product\n",
    "\n",
    "    #Scrape images from 7 pages : \n",
    "    for page in range(1,8):\n",
    "        product_list = url+product+\"&page=\"+str(page)\n",
    "        #print(product_list)\n",
    "        product_urls.append(product_list)\n",
    "    \n",
    "    for url in product_urls:\n",
    "        driver.get(url)\n",
    "        images = driver.find_elements_by_xpath(\"//img[@class='s-image']\")\n",
    "        for i in images:\n",
    "            src = i.get_attribute(\"src\")\n",
    "            img_list.append(src)\n",
    "            time.sleep(0.10)\n",
    "    \n",
    "    #Download the images:\n",
    "    for count,imgs in enumerate(img_list):\n",
    "        image_name = path+ \"/pic_\" + str(count) + \".jpg\"\n",
    "        file,header = urllib.request.urlretrieve(imgs,image_name)\n",
    "\n",
    "    print(\"Downloaded \", len(img_list), \" images of \", c,\"\\n\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
